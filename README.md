# DDP Training Project with Slurm

This repository provides a minimal example of distributed training using PyTorch's `DistributedDataParallel` (DDP) on a Slurm-managed cluster.
